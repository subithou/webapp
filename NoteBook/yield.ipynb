{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2347feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cwd = os.getcwd()\n",
    "# df_2013 = pd.read_pickle(os.path.join(cwd,'data','df_2013_features.df'))\n",
    "# df_2014 = pd.read_pickle(os.path.join(cwd,'data','df_2014_features.df'))\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv(r\"D:\\SREE\\Project\\yield_prediction\\data\\Crop_yield_cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3f36211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Latitude   Longitude  apparentTemperatureMax  apparentTemperatureMin   \n",
      "0  46.811686 -118.695237                   35.70                   20.85  \\\n",
      "1  46.929839 -118.352109                   35.10                   26.92   \n",
      "2  47.006888 -118.510160                   33.38                   26.95   \n",
      "3  47.162342 -118.699677                   28.05                   25.93   \n",
      "4  47.157512 -118.434056                   28.83                   25.98   \n",
      "\n",
      "   cloudCover  dewPoint  humidity  precipIntensity  precipIntensityMax   \n",
      "0        0.00     29.53      0.91           0.0000              0.0000  \\\n",
      "1        0.00     29.77      0.93           0.0001              0.0019   \n",
      "2        0.00     29.36      0.94           0.0001              0.0022   \n",
      "3        0.91     29.47      0.94           0.0002              0.0039   \n",
      "4        0.91     29.86      0.94           0.0003              0.0055   \n",
      "\n",
      "   precipProbability  ...  precipTypeIsOther  pressure  temperatureMax   \n",
      "0               0.00  ...                  0   1027.13           35.70  \\\n",
      "1               0.05  ...                  0   1026.87           35.10   \n",
      "2               0.06  ...                  0   1026.88           33.38   \n",
      "3               0.15  ...                  0   1026.37           33.19   \n",
      "4               0.24  ...                  0   1026.19           33.85   \n",
      "\n",
      "   temperatureMin  visibility  windBearing  windSpeed        NDVI   \n",
      "0           27.48        2.46          214       1.18  134.110657  \\\n",
      "1           26.92        2.83          166       1.01  131.506592   \n",
      "2           26.95        2.95          158       1.03  131.472946   \n",
      "3           27.17        2.89          153       1.84  131.288300   \n",
      "4           27.07        2.97          156       1.85  131.288300   \n",
      "\n",
      "   DayInSeason  yield  \n",
      "0            0   35.7  \n",
      "1            0   35.7  \n",
      "2            0   35.7  \n",
      "3            0   35.7  \n",
      "4            0   35.7  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b802c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df_all['yield']\n",
    "X = df_all.drop('yield',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4f39377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         35.7\n",
      "1         35.7\n",
      "2         35.7\n",
      "3         35.7\n",
      "4         35.7\n",
      "          ... \n",
      "360037    50.1\n",
      "360038    50.1\n",
      "360039    50.1\n",
      "360040    50.1\n",
      "360041    50.1\n",
      "Name: yield, Length: 360042, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d706d0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Latitude', 'Longitude', 'apparentTemperatureMax', 'apparentTemperatureMin', 'cloudCover', 'dewPoint', 'humidity', 'precipIntensity', 'precipIntensityMax', 'precipProbability', 'precipAccumulation', 'precipTypeIsRain', 'precipTypeIsSnow', 'precipTypeIsOther', 'pressure', 'temperatureMax', 'temperatureMin', 'visibility', 'windBearing', 'windSpeed', 'NDVI', 'DayInSeason']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "columns_to_scale = df_all.columns.tolist()\n",
    "columns_to_scale = [x for x in columns_to_scale if x != 'yield']\n",
    "print(columns_to_scale)\n",
    "\n",
    "std_scaler = preprocessing.StandardScaler().fit(X_train[columns_to_scale])\n",
    "minmax_scaler = preprocessing.MinMaxScaler().fit(X_train[columns_to_scale])\n",
    "\n",
    "X_train[columns_to_scale] = std_scaler.transform(X_train[columns_to_scale])\n",
    "# X_train[columns_to_scale] = minmax_scaler.transform(X_train[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5377b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to apply the scaler also to the test set.\n",
    "X_test[columns_to_scale] = std_scaler.transform(X_test[columns_to_scale])\n",
    "# X_test[columns_to_scale] = minmax_scaler.transform(X_test[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5b90851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cros validation. Set 'k' and the scoring function. If scoring function is not set, \n",
    "# cross_val_score will use the default scoring for the respective estimator. To make sure \n",
    "# I compare all estimators on the same scale, I set the scoring function explicitly.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_k = 5\n",
    "cv_scoring = 'neg_mean_squared_error'\n",
    "cv_scoring = 'r2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "768fb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=cv_k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4957bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39bdd262",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Linear regression\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m now \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      3\u001b[0m est \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[0;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(est, X_train, y_train, cv\u001b[38;5;241m=\u001b[39mkf, scoring\u001b[38;5;241m=\u001b[39mcv_scoring)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# Linear regression\n",
    "now = time.time()\n",
    "est = linear_model.LinearRegression()\n",
    "scores = cross_val_score(est, X_train, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4819c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with L2 regularization\n",
    "now = time.time()\n",
    "est = linear_model.Ridge(alpha = 1.0)\n",
    "scores = cross_val_score(est, X_train, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with L2 regularization\n",
    "now = time.time()\n",
    "est = linear_model.Ridge(alpha = 1.0)\n",
    "scores = cross_val_score(est, X_train, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5283d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression\n",
    "now = time.time()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "est = linear_model.LinearRegression()\n",
    "scores = cross_val_score(est, X_train_poly, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial regression with regularization\n",
    "now = time.time()\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "est = linear_model.Ridge(alpha = 1.0)\n",
    "scores = cross_val_score(est, X_train_poly, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest regression\n",
    "now = time.time()\n",
    "est = RandomForestRegressor(n_estimators=10, n_jobs=-1)\n",
    "scores = cross_val_score(est, X_train, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosted regression\n",
    "now = time.time()\n",
    "est = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
    "                                max_depth=0.3, random_state=0, loss='ls')\n",
    "scores = cross_val_score(est, X_train, y_train, cv=kf, scoring=cv_scoring)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "after = time.time()\n",
    "print('Exec. time: {:5.2f} s'.format(after-now))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
